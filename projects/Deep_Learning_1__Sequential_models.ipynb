{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.estimator import DNNRegressor, LinearRegressor \n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, add, Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD \n",
    "from keras.callbacks import EarlyStopping \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Deep learning models with keras\n",
    "- deep networks: many layers, capture a lot of interactions and partially reduce the need for feature engineering\n",
    "- deep learning also called representation learning because subsequent layers build increasingly more sophisticated representations of the data\n",
    "- with images, first layers identify simple patterns, subsequent layers combine those to identify complex objects\n",
    "\n",
    "- nodes and weights:\n",
    "  - each node represents interactions between certain input features or nodes in previous layers (the more nodes, the more interactions we capture)\n",
    "  - each line has a weight (represent coefficients in regression) reflecting how much the input affects the hidden node that the line ends at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 steps:\n",
    "- specify architecture: how many layers, how many nodes in each layer (nodes in input just given by data), activation function in each layer\n",
    "  - sequential: layers connect to layers directly after\n",
    "  - dense: all nodes in previous layer connect with all nodes in new layer\n",
    "  - input_shape = (n_cols,) n_cols and any number of rows\n",
    "- compile: specify loss function (MSE is default for regression) and optimization (Adam is a good first choice, adaptive moment estimation)\n",
    "- fit: cycle of back propagation and update of model weights with data\n",
    "  - batches: chuncks of data, epochs: number of times trained on all batches\n",
    "- predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - activation function\n",
    "- activation functions: non linearity between features and targets - act on node values (not weights)\n",
    "- sigmoid: binary classification\n",
    "- ReLu (rectified linear unit): hidden layers,  =max(0,X)\n",
    "- **for regression use 'relu' in hidden layers, nothing in output layer**\n",
    "- **for classification use 'relu' in hidden layers, 'softmax' in output layer with >2 classes otherwise sigmoid**\n",
    "  \n",
    "- critical and may cause dying neuron: neuron takes values <0 for all rows of data, so slopes are 0 and weights don't get updated \n",
    "  - can be corrected with activation functions for which slopes are small but never zero which works with a few layers\n",
    "  - for many layers this causes vanishing gradient problem, they get very close to zero with backprop\n",
    "  - non flat below zero don't seem to work\n",
    "\n",
    "  \n",
    "\n",
    "  \n",
    "\n",
    "<img src=\"./img/activation_functions.png\" align=\"left\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Optimizing a neural network: backward propagation\n",
    "- gradient descent: update weights by slope*learning rate (tipically lr=0.01, small steps to make sure we keep moving down)\n",
    "- calculated using: input value into the node, slope of loss function with respect to each weight (found by comparing output with target), slope of activation function\n",
    "- back propagation: update weights backwards from output\n",
    "  - first do forward propagation to compute error, then do back propagation\n",
    "  - by the time we do back propagation the slope of loss function has been calculated\n",
    "- normally calculate slopes in batches for each update of the weights (stochastic gradients descent, SGD), when all batches have been used 1 epoch is completed\n",
    "\n",
    "**Optimizers**:\n",
    "- Stocastic Gradient Descent (SGD): fast and avoids getting stuck in local minimum\n",
    "  - learning rate: 0.01 - 0.5 (higher learning rate, faster drop of ball, but it might miss global minima)\n",
    "- Root mean square (RMS) propgation optimizer\n",
    "  - different learning rates to each feature\n",
    "  - decay parameter which helps escape local minimum\n",
    "- Adaptive momentum optimizer (Adam)\n",
    "  - beta1 and beta2 parameters, increase to lower chance of getting stuck on local minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Trainning (initializer and dropout)\n",
    "- Dense layers are initialized with glorot initializer by default: initialize thousands of variables randomly to avoid local minimum\n",
    "  - alternatively specify tf.keras.layers.Dense(..., kernel_initializer='zeros')\n",
    "- avoid overfitting: memorize points instead of learning pattern\n",
    "  - dropout, randomly drop nodes from a layer: more robust classification that does not rely on particular nodes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 - Model or Network capacity: validation score\n",
    "- ability to find predictive patterns in data \n",
    "- create a small network then keep adding capacity as long as score keeps improving\n",
    "  - increase number of hidden layers or number of hidden nodes (start with nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/bias_variance.png' align='left' style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 - Neural Nets with Keras: \n",
    "\n",
    "- Sequential API: input layer, hidden layers, output layers in sequence (don't need to pass layers into next ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_477 (Dense)            (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "dense_478 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_479 (Dense)            (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 220\n",
      "Trainable params: 220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, activation='relu', input_shape=(2,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile('adam', loss='categorical_crossentropy')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Functional API: two models with different inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_480 (Dense)               (None, 12)           36          input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_482 (Dense)               (None, 8)            24          input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_481 (Dense)               (None, 4)            52          dense_480[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_483 (Dense)               (None, 4)            36          dense_482[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 4)            0           dense_481[0][0]                  \n",
      "                                                                 dense_483[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 148\n",
      "Trainable params: 148\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "m1_inputs = Input(shape=(2,))\n",
    "m1_layer1 = Dense(12, activation='sigmoid')(m1_inputs)\n",
    "m1_layer2 = Dense(4, activation='softmax')(m1_layer1)\n",
    "\n",
    "m2_inputs = Input(shape=(2,))\n",
    "m2_layer1 = Dense(8, activation='relu')(m2_inputs)\n",
    "m2_layer2 = Dense(4, activation='softmax')(m2_layer1)\n",
    "\n",
    "merged = add([m1_layer2, m2_layer2])\n",
    "model = Model(inputs=[m1_inputs, m2_inputs], outputs=merged)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2 - Regression problem to predict hourly_wages: \n",
    "- optimizer='adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/hourly_wages.csv')\n",
    "train_df = df[:int(len(df)*0.9)]\n",
    "test_df = df[int(len(df)*0.9):]\n",
    "\n",
    "train_features_df = train_df.drop('wage_per_hour', axis=1)\n",
    "train_target_df = train_df['wage_per_hour']\n",
    "\n",
    "test_features_df = test_df.drop('wage_per_hour', axis=1)\n",
    "test_target_df = test_df['wage_per_hour']\n",
    "\n",
    "n_features = features_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 200us/step\n",
      "Evaluation score: 5.91\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_features,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#print(\"Loss function: \" + model.loss)\n",
    "model.fit(train_features_df, train_target_df, epochs=10, validation_split=0.3, verbose=False)\n",
    "score = model.evaluate(test_features_df, test_target_df)\n",
    "\n",
    "print(f\"Evaluation score: {np.sqrt(score):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3 - Binary Classification for Titanic survival: \n",
    "- loss='categorical_crossentropy', metrics=['accuracy']\n",
    "- final layer needs one node for each outcome, with softmax activation (ensure predictions add up to one and can be interpreted as probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/titanic_all_numeric.csv')\n",
    "train_df = df[:int(len(df)*0.9)]\n",
    "test_df = df[int(len(df)*0.9):]\n",
    "\n",
    "train_features_df = train_df.drop('survived', axis=1)\n",
    "train_target_df = to_categorical(train_df['survived'])\n",
    "\n",
    "test_features_df = test_df.drop('survived', axis=1)\n",
    "test_target_df = to_categorical(test_df['survived'])\n",
    "\n",
    "n_features = features_df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - simple sequential model, fit, evaluate and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 200us/step\n",
      "Evaluation accuracy: 0.66\n",
      "[0.2000058  0.5054923  0.22789302 0.4535593  0.13145064]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(train_features_df, train_target_df, epochs=10, verbose=False, validation_split=0.3, \n",
    "          callbacks=[early_stopping_monitor])\n",
    "score = model.evaluate(test_features_df, test_target_df)\n",
    "print(f\"Evaluation accuracy: {score[1]:0.2f}\")\n",
    "\n",
    "model.save('./models/titanic_model.h5')\n",
    "\n",
    "predictions = model.predict(predictors)\n",
    "predicted_prob_true = predictions[:,1]\n",
    "\n",
    "# print predicted_prob_true\n",
    "print(predicted_prob_true[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "Evaluation accuracy: 0.38\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "Evaluation accuracy: 0.62\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "Evaluation accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "def get_new_model(input_shape):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    return (model)\n",
    "\n",
    "lr_to_test = [0.000001, 0.01, 1]\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\nTesting model with learning rate: %f'%lr )\n",
    "    \n",
    "    model = get_new_model((n_cols,))   \n",
    "    model.compile(optimizer=SGD(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])    \n",
    "    model.fit(train_features_df, train_target_df, epochs=10, verbose=False, validation_split=0.3, \n",
    "              callbacks=[early_stopping_monitor])\n",
    "    score = model.evaluate(test_features_df, test_target_df, verbose=False)\n",
    "    print(f\"Evaluation accuracy: {score[1]:0.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Validation\n",
    "- k-fold is uncommon because data is very large\n",
    "- earlystopping patience: how many epochs the model can go without imporving before we stop trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy model 1: 0.71\n",
      "Evaluation accuracy model 2: 0.74\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model_1\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(10, activation='relu', input_shape = (n_cols,)))\n",
    "model_1.add(Dense(10, activation='relu'))\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    "\n",
    "#model_2\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "model_2.add(Dense(50, activation='relu'))\n",
    "model_2.add(Dense(50, activation='relu'))\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_1_training = model_1.fit(train_features_df, train_target_df, epochs=20, validation_split=0.3, \n",
    "                               callbacks=[early_stopping_monitor], verbose=False)\n",
    "model_2_training = model_2.fit(train_features_df, train_target_df, epochs=20, validation_split=0.3, \n",
    "                               callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "score = model_1.evaluate(test_features_df, test_target_df, verbose=False)\n",
    "print(f\"Evaluation accuracy model 1: {score[1]:0.2f}\")\n",
    "score = model_2.evaluate(test_features_df, test_target_df, verbose=False)\n",
    "print(f\"Evaluation accuracy model 2: {score[1]:0.2f}\")\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 4 - MultiClassification for Hand written numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/mnist.csv', header=None)\n",
    "train_df = df[:int(len(df)*0.9)]\n",
    "test_df = df[int(len(df)*0.9):]\n",
    "\n",
    "y_train  = to_categorical(train_df.iloc[:,0])\n",
    "X_train = train_df.iloc[:,1:]\n",
    "\n",
    "y_test  = to_categorical(test_df.iloc[:,0])\n",
    "X_test = test_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy model 2: 0.69\n"
     ]
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=5)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(20, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(20, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(20, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train,y_train,validation_split=0.3, verbose=False, epochs=50, callbacks=[early_stopping_monitor])\n",
    "score = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(f\"Evaluation accuracy: {score[1]:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 5 - MultiClassification for 4 signs from sign language\n",
    "- dataset: 2000 sign language images (first column 0 to 3 to represent each of 4 signs), additional 784 columns represent 28x28 pixel image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=5)\n",
    "\n",
    "df = pd.read_csv('./data/slmnist.csv', header=None, dtype=np.float64)\n",
    "\n",
    "target_df = np.array(pd.get_dummies(df.iloc[:,0]))\n",
    "features_df = df.iloc[:,1:]\n",
    "features_df = pd.DataFrame(MinMaxScaler().fit_transform(features_df), columns=features_df.columns)\n",
    "\n",
    "train_features_df = features_df[:int(len(features_df)*0.9)]\n",
    "train_target_df = target_df[:int(len(target_df)*0.9)]\n",
    "\n",
    "test_features_df = features_df[int(len(features_df)*0.9):]\n",
    "test_target_df = target_df[int(len(target_df)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation train accuracy: 0.91\n",
      "Evaluation test accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile('SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_features_df, train_target_df, validation_split=0.3, verbose=False, epochs=5, \n",
    "          callbacks=[early_stopping_monitor])\n",
    "\n",
    "score = model.evaluate(test_features_df, test_target_df, verbose=False)\n",
    "print(f\"Evaluation train accuracy: {score[1]:0.2f}\")\n",
    "score = model.evaluate(train_features_df, train_target_df, verbose=False)\n",
    "print(f\"Evaluation test accuracy: {score[1]:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation train accuracy: 0.94\n",
      "Evaluation test accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile('SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_features_df, train_target_df, validation_split=0.3, verbose=False, epochs=5, \n",
    "          callbacks=[early_stopping_monitor])\n",
    "\n",
    "score = model.evaluate(test_features_df, test_target_df, verbose=False)\n",
    "print(f\"Evaluation train accuracy: {score[1]:0.2f}\")\n",
    "score = model.evaluate(train_features_df, train_target_df, verbose=False)\n",
    "print(f\"Evaluation test accuracy: {score[1]:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation train accuracy: 0.95\n",
      "Evaluation test accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile('SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_features_df, train_target_df, validation_split=0.3, verbose=False, epochs=5, \n",
    "          callbacks=[early_stopping_monitor])\n",
    "\n",
    "score = model.evaluate(test_features_df, test_target_df, verbose=False)\n",
    "print(f\"Evaluation train accuracy: {score[1]:0.2f}\")\n",
    "score = model.evaluate(train_features_df, train_target_df, verbose=False)\n",
    "print(f\"Evaluation test accuracy: {score[1]:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation train accuracy: 0.86\n",
      "Evaluation test accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile('SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_features_df, train_target_df, validation_split=0.3, verbose=False, epochs=5, \n",
    "          callbacks=[early_stopping_monitor])\n",
    "\n",
    "score = model.evaluate(test_features_df, test_target_df, verbose=False)\n",
    "print(f\"Evaluation train accuracy: {score[1]:0.2f}\")\n",
    "score = model.evaluate(train_features_df, train_target_df, verbose=False)\n",
    "print(f\"Evaluation test accuracy: {score[1]:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 6 - High level Estimators: predict House Prices \n",
    "- high level: Estimators - enforces best practices, faster deployment, less flexibility\n",
    "- mid level: layers, datasets, metrics\n",
    "- low level: python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('./data/kc_house_data.csv')\n",
    "\n",
    "bedrooms = tf.feature_column.numeric_column(\"bedrooms\")\n",
    "bathrooms = tf.feature_column.numeric_column(\"bathrooms\")\n",
    "sqft_living = tf.feature_column.numeric_column(\"sqft_living\")\n",
    "\n",
    "# Define the list of feature columns\n",
    "feature_list = [bedrooms, bathrooms, sqft_living]\n",
    "\n",
    "def input_fn():\n",
    "    labels = np.array(housing['price'])\n",
    "    features = {'bedrooms':np.array(housing['bedrooms']), \n",
    "                'bathrooms':np.array(housing['bathrooms']),\n",
    "                'sqft_living':np.array(housing['sqft_living'])\n",
    "               }\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/0z/4fv_kbd53yjd5q8jnf62dk0w0000gn/T/tmp8zzyq0m2\n",
      "{'average_loss': 68717790000.0, 'label/mean': 540088.1, 'loss': 1485197500000000.0, 'prediction/mean': 541660.4, 'global_step': 100}\n",
      "Mean error from evaluation: 262140.78\n"
     ]
    }
   ],
   "source": [
    "model = DNNRegressor(feature_columns=feature_list, hidden_units=[4,200])\n",
    "model_trainning = model.train(input_fn, steps=100)\n",
    "score = model.evaluate(input_fn, steps=10)\n",
    "print(score)\n",
    "print(f\"Mean error from evaluation: {np.sqrt(score['average_loss']):0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/0z/4fv_kbd53yjd5q8jnf62dk0w0000gn/T/tmp24hg78_8\n",
      "{'average_loss': 403382400000.0, 'label/mean': 540087.25, 'loss': 8718303600000000.0, 'prediction/mean': 17955.258, 'global_step': 500}\n",
      "Mean error from evaluation: 635123.94\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.LinearRegressor(feature_columns=feature_list)\n",
    "model_trainning = model.train(input_fn, steps=500)\n",
    "score = model.evaluate(input_fn, steps=500)\n",
    "print(score)\n",
    "print(f\"Mean error from evaluation: {np.sqrt(score['average_loss']):0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
