{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: ML - Logistic Regression, One-versus-all Method for MultiClass Classification + RFC & GBC (Car Origins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem:\n",
    "- Predict continent of origin from technical car properties: year built, cylinders, horsepower, weight, mpg, acceleration, etc\n",
    "- MultiClass Classification (USA - 1, Europe - 2 or Asia - 3) with LogisticRegression + one-vs-all-method, RandomForestClassifier & GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Tools:\n",
    "- Feature Engineering: Dummy coding, RFECV\n",
    "- Models: LogisticRegression + one-vs-all-method, RandomForestClassifier & GradientBoostingClassifier\n",
    "- Model validation and hyperparameter search: GridSearchCV, K-fold validation and predictions\n",
    "- Error Metrics: Accuracy, TPR, TNR, MCC, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### load defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaults Loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import requests \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Math\n",
    "\n",
    "from functions import *\n",
    "import myML_functions as myML_functions\n",
    "\n",
    "plt.rcParams.update({'axes.titlepad': 20, 'font.size': 12, 'axes.titlesize':20})\n",
    "\n",
    "colors = [(0/255,107/255,164/255), (255/255, 128/255, 14/255), 'red', 'green', '#9E80BA', '#8EDB8E', '#58517A']\n",
    "Ncolors = 10\n",
    "color_map = plt.cm.Blues_r(np.linspace(0.2, 0.5, Ncolors))\n",
    "#color_map = plt.cm.tab20c_r(np.linspace(0.2, 0.5, Ncolors))\n",
    "\n",
    "\n",
    "#specific to this project\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_predict\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
    "\n",
    "print(\"Defaults Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Dataset: car properties and continent of origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    245\n",
      "3     79\n",
      "2     68\n",
      "Name: origin, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cars = pd.read_csv(\"./data/auto.csv\")\n",
    "\n",
    "#find unique values\n",
    "unique_regions = cars['origin'].unique()\n",
    "print(cars['origin'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dummy coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>origin</th>\n",
       "      <th>cyl_3</th>\n",
       "      <th>cyl_4</th>\n",
       "      <th>cyl_5</th>\n",
       "      <th>cyl_6</th>\n",
       "      <th>cyl_8</th>\n",
       "      <th>year_70</th>\n",
       "      <th>year_71</th>\n",
       "      <th>year_72</th>\n",
       "      <th>year_73</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  displacement  horsepower  weight  acceleration  origin  cyl_3  cyl_4  \\\n",
       "0  18.0         307.0       130.0  3504.0          12.0       1      0      0   \n",
       "1  15.0         350.0       165.0  3693.0          11.5       1      0      0   \n",
       "2  18.0         318.0       150.0  3436.0          11.0       1      0      0   \n",
       "\n",
       "   cyl_5  cyl_6  cyl_8  year_70  year_71  year_72  year_73  \n",
       "0      0      0      1        1        0        0        0  \n",
       "1      0      0      1        1        0        0        0  \n",
       "2      0      0      1        1        0        0        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#categoric columns: cylinders, year, origin\n",
    "\n",
    "#set prefix\n",
    "dummy_cylinders = pd.get_dummies(cars[\"cylinders\"], prefix=\"cyl\")\n",
    "cars = pd.concat([cars, dummy_cylinders], axis=1)\n",
    "\n",
    "dummy_years = pd.get_dummies(cars['year'], prefix='year')\n",
    "cars = pd.concat([cars, dummy_years], axis = 1)\n",
    "cars.drop(['cylinders','year'], axis=1, inplace=True)\n",
    "\n",
    "display(cars.iloc[:3,:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shuffle rows and split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "shuffled_cars = cars.iloc[np.random.permutation(len(cars))]\n",
    "\n",
    "train = shuffled_cars[0: int(0.7*len(shuffled_cars))]\n",
    "test = shuffled_cars[int(0.7*len(shuffled_cars)):]\n",
    "\n",
    "df_clean = shuffled_cars\n",
    "target = 'origin'\n",
    "target_df = df_clean['origin']\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1 - Logistic Regression Model: One-versus-all method\n",
    "\n",
    "- Logistic Regression outputs a probability value (that a given row should be labeled 1). In binary classification we can set a threshold and assign 1 to probability values above and 0 below. treshold = 0.5 in LogisticRegression by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One versus all method for Multiclass Classification:** choose one category as the positive case and group all others in the False case\n",
    "- convert the problem into n binary classification problems\n",
    "- train 3 models: \n",
    "  - cars made in America = 1, Europe and Asia = 0\n",
    "  - cars made in Europe = 1, America and Asia = 0\n",
    "  - cars made in Asia = 1, America and Europe = 0\n",
    "\n",
    "then, for each observations choose the model the label (prediction) with highest probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models fitted\n"
     ]
    }
   ],
   "source": [
    "unique_origins = cars[\"origin\"].unique()\n",
    "unique_origins.sort()\n",
    "\n",
    "models = {}\n",
    "\n",
    "#train model just with year and cylinder dummy columns\n",
    "cols = train.columns\n",
    "cols_to_keep = (cols.str.contains('cyl') | cols.str.contains('year'))\n",
    "\n",
    "testing_probs = pd.DataFrame(columns=unique_origins)\n",
    "\n",
    "#train on train set\n",
    "X = train[cols[cols_to_keep]]\n",
    "for element in unique_origins:\n",
    "    #select only rows with current label\n",
    "    y = train['origin'] == element\n",
    "    models[element] = LogisticRegression(solver='lbfgs')\n",
    "    models[element].fit(X, y)\n",
    "\n",
    "print(\"models fitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.958401</td>\n",
       "      <td>0.035453</td>\n",
       "      <td>0.018950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.979050</td>\n",
       "      <td>0.013642</td>\n",
       "      <td>0.023675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.277985</td>\n",
       "      <td>0.356383</td>\n",
       "      <td>0.351180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.983759</td>\n",
       "      <td>0.013213</td>\n",
       "      <td>0.018183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.340172</td>\n",
       "      <td>0.261673</td>\n",
       "      <td>0.377821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3\n",
       "0  0.958401  0.035453  0.018950\n",
       "1  0.979050  0.013642  0.023675\n",
       "2  0.277985  0.356383  0.351180\n",
       "3  0.983759  0.013213  0.018183\n",
       "4  0.340172  0.261673  0.377821"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#predict\n",
    "y = test[cols[cols_to_keep]]    \n",
    "for element in unique_origins:\n",
    "    testing_probs[element]=models[element].predict_proba(y)[:,1]\n",
    "    \n",
    "display(testing_probs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    1\n",
       "4    3\n",
       "Name: predicted_label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_origins = testing_probs.idxmax(axis=1)\n",
    "cars['predicted_label'] = predicted_origins\n",
    "cars.dropna(axis=0, inplace=True, how='any')\n",
    "cars['predicted_label'] = cars['predicted_label'].astype('int')\n",
    "display(cars['predicted_label'].iloc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.2 - Error Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.492\n"
     ]
    }
   ],
   "source": [
    "cars = cars.rename(columns={'origin': 'actual_label'})\n",
    "matches = cars['actual_label']==cars['predicted_label']\n",
    "correct_predictions = cars[matches]\n",
    "\n",
    "accuracy = len(correct_predictions)/len(cars)\n",
    "print(\"Accuracy = {:0.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall/Sensitivity(True Positive Rate)**, $TPR = \\frac{True\\,Positives}{True\\,Positives+False\\,Negatives}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity = 0.492\n"
     ]
    }
   ],
   "source": [
    "true_positives = 0\n",
    "for element in  cars[\"actual_label\"].unique():\n",
    "    my_filter = (cars[\"predicted_label\"] == element) & (cars[\"actual_label\"] == element)\n",
    "    true_positives += len(cars[my_filter])\n",
    "    \n",
    "false_negatives = 0\n",
    "for element in  cars[\"actual_label\"].unique():\n",
    "    my_filter = (cars[\"predicted_label\"] != element) & (cars[\"actual_label\"] == element)\n",
    "    false_negatives += len(cars[my_filter])    \n",
    "    \n",
    "sensitivity = (true_positives)/(true_positives+false_negatives)\n",
    "print(\"Sensitivity = {:0.3f}\".format(sensitivity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specificity (True Negative rate)**, $TNR = \\frac{True\\,Negatives}{False\\,Positives+True\\,Negatives}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity = 0.746\n"
     ]
    }
   ],
   "source": [
    "true_negatives = 0\n",
    "for element in  cars[\"actual_label\"].unique():\n",
    "    my_filter = (cars[\"predicted_label\"] != element) & (cars[\"actual_label\"] != element)\n",
    "    true_negatives += len(cars[my_filter])\n",
    "    \n",
    "false_positives = 0\n",
    "for element in  cars[\"actual_label\"].unique():\n",
    "    my_filter = (cars[\"predicted_label\"] == element) & (cars[\"actual_label\"] != element)\n",
    "    false_positives += len(cars[my_filter])  \n",
    "    \n",
    "specificity = true_negatives/(true_negatives+false_positives)\n",
    "print(\"Specificity = {:0.3f}\".format(specificity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matthew's Correlation Coefficient**, $MCC = \\frac{TP.TN-FP.FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC = 0.237\n"
     ]
    }
   ],
   "source": [
    "MCC = ((true_positives*true_negatives-false_positives*false_negatives)/\n",
    "       np.sqrt((true_positives+false_positives)*(true_positives+false_negatives)*\n",
    "        (true_negatives+false_positives)*(true_negatives+false_negatives)))\n",
    "print(\"MCC = {:0.3f}\".format(MCC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.62      0.68        86\n",
      "           2       0.11      0.17      0.13        18\n",
      "           3       0.10      0.14      0.12        14\n",
      "\n",
      "   micro avg       0.49      0.49      0.49       118\n",
      "   macro avg       0.32      0.31      0.31       118\n",
      "weighted avg       0.57      0.49      0.53       118\n",
      "\n",
      "    true / pred    USA (1) Europe (2)   Asia (3) \n",
      "       USA (1)       53.0       19.0       14.0 \n",
      "    Europe (2)       11.0        3.0        4.0 \n",
      "      Asia (3)        7.0        5.0        2.0 \n"
     ]
    }
   ],
   "source": [
    "print(classification_report(cars['actual_label'],cars['predicted_label']))\n",
    "cm = confusion_matrix(cars['actual_label'], cars['predicted_label'], labels=[1, 2, 3])\n",
    "myML_functions.print_cm(cm, labels=['USA (1)', 'Europe (2)', ' Asia (3)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2 - Feature Selection with RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Columns, LogisticRegression model: ['mpg', 'displacement', 'horsepower', 'weight', 'acceleration', 'cyl_3', 'cyl_4', 'cyl_5', 'cyl_6', 'cyl_8', 'year_70', 'year_71', 'year_72', 'year_73', 'year_74', 'year_75', 'year_76', 'year_77', 'year_78', 'year_79', 'year_80', 'year_81', 'year_82']\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "Best Columns, RandomForestClassifier model: ['mpg', 'displacement', 'horsepower', 'weight', 'acceleration', 'cyl_4']\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "Best Columns, GradientBoostingClassifier model: ['mpg', 'displacement', 'horsepower', 'weight', 'acceleration', 'cyl_3', 'cyl_4', 'cyl_5', 'cyl_6', 'year_82']\n",
      "\n",
      "----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver = 'lbfgs', class_weight='balanced', max_iter=3000, multi_class='ovr')\n",
    "optimized_columns_LR = myML_functions.select_features_RFECV(df_clean, target, model)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50, random_state=1, min_samples_leaf=5, class_weight='balanced')\n",
    "optimized_columns_RFC = myML_functions.select_features_RFECV(df_clean, target, model)\n",
    "\n",
    "model = GradientBoostingClassifier(learning_rate=0.01, n_estimators=50,subsample=0.6,random_state=42)  \n",
    "optimized_columns_GBC = myML_functions.select_features_RFECV(df_clean, target, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3 - Model Selection with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(df, target, models_to_fit):                              \n",
    "                              \n",
    "    dicts= [ {\n",
    "               \"name\": \"LogisticRegression\",\n",
    "               \"estimator\": LogisticRegression(max_iter = 100000, multi_class='auto'),\n",
    "               \"hyperparameters\": \n",
    "                 {                \n",
    "                   \"solver\": [\"lbfgs\", \"liblinear\"],  \n",
    "                   \"class_weight\": [\"balanced\", \"\"]                      \n",
    "                 }\n",
    "             },             \n",
    "             {\n",
    "               \"name\": \"RandomForestClassifier\",\n",
    "               \"estimator\": RandomForestClassifier(),\n",
    "               \"hyperparameters\": \n",
    "                 {\n",
    "                   \"n_estimators\": [5, 20, 100],\n",
    "                   \"criterion\": [\"entropy\", \"gini\"],\n",
    "                   \"max_depth\": [2, 5, 10],\n",
    "                   \"max_features\": [\"log2\", \"sqrt\"],\n",
    "                   \"min_samples_leaf\": [1, 5, 8],\n",
    "                   \"min_samples_split\": [2, 3, 5], \n",
    "                   \"class_weight\": [None, \"balanced\"]               \n",
    "                 }\n",
    "             },\n",
    "             {\n",
    "               \"name\": \"GradientBoostingClassifier\",\n",
    "               \"estimator\": GradientBoostingClassifier(),\n",
    "               \"hyperparameters\": \n",
    "                 {\n",
    "                   \"n_estimators\": [5, 2, 10],  \n",
    "                   \"max_features\": [\"auto\", \"log2\", \"sqrt\"],\n",
    "                   \"learning_rate\":[0.01, 0.05, 0.1, 0.5],\n",
    "                   \"subsample\":[0.1, 0.5, 1.0],  \n",
    "                   \"random_state\":[1]     \n",
    "                 }\n",
    "             }]    \n",
    "    \n",
    "    scoring = {'Accuracy':'accuracy', \n",
    "               'precision': make_scorer(precision_score, average='weighted'),\n",
    "               'recall': make_scorer(recall_score, average='weighted'),\n",
    "               'f1': make_scorer(f1_score, average='weighted')}\n",
    "    \n",
    "    all_y = df[target]\n",
    "    \n",
    "    for key, models_list in models_to_fit.items():        \n",
    "        print(key)\n",
    "        print('-'*len(key))\n",
    "        start = time.time()\n",
    "        for element in dicts:\n",
    "            if models_list[0] == element['name']:                \n",
    "                all_X = df[models_list[1]]              \n",
    "                model = element['estimator']\n",
    "                grid = GridSearchCV(model, element['hyperparameters'], cv=10, scoring=scoring, \n",
    "                                    refit='f1', iid=True, n_jobs=1)\n",
    "                grid.fit(all_X, all_y)\n",
    "        \n",
    "                element['best_params'] = grid.best_params_\n",
    "                element['best_score'] = grid.best_score_\n",
    "                element['best_estimator'] = grid.best_estimator_          \n",
    "                for scorer in scoring:          \n",
    "                    print(f\"{scorer}: {max(grid.cv_results_['mean_test_'+scorer]):0.3f}\")\n",
    "                print(\"Best Parameters: {}\".format(grid.best_params_))\n",
    "                print(\"Best Score: {:0.3f}\\n\".format(grid.best_score_))\n",
    "        \n",
    "        print(f\"Time elapsed: {(time.time()-start)/60.:0.2f} mins\\n\\n\")\n",
    "        #for scorer in scoring:\n",
    "        #    print(cv_results_'_<scorer_name>')\n",
    "       \n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "------------------\n",
      "Accuracy: 0.765\n",
      "precision: 0.800\n",
      "recall: 0.765\n",
      "f1: 0.769\n",
      "Best Parameters: {'class_weight': 'balanced', 'solver': 'liblinear'}\n",
      "Best Score: 0.769\n",
      "\n",
      "Time elapsed: 0.23 mins\n",
      "\n",
      "\n",
      "RandomForestClassifier\n",
      "----------------------\n",
      "Accuracy: 0.890\n",
      "precision: 0.900\n",
      "recall: 0.890\n",
      "f1: 0.887\n",
      "Best Parameters: {'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Score: 0.887\n",
      "\n",
      "Time elapsed: 13.87 mins\n",
      "\n",
      "\n",
      "GradientBoostingClassifier\n",
      "--------------------------\n",
      "Accuracy: 0.852\n",
      "precision: 0.863\n",
      "recall: 0.852\n",
      "f1: 0.849\n",
      "Best Parameters: {'learning_rate': 0.5, 'max_features': 'auto', 'n_estimators': 10, 'random_state': 1, 'subsample': 1.0}\n",
      "Best Score: 0.849\n",
      "\n",
      "Time elapsed: 0.63 mins\n",
      "\n",
      "\n",
      "model selection finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "import time\n",
    "  \n",
    "models_to_fit = {'LogisticRegression': ['LogisticRegression', optimized_columns_LR],                    \n",
    "                 'RandomForestClassifier': ['RandomForestClassifier', optimized_columns_RFC],\n",
    "                 'GradientBoostingClassifier': ['GradientBoostingClassifier', optimized_columns_GBC]}\n",
    "\n",
    "model_dicts = select_model(df_clean[:int(len(df_clean))], target, models_to_fit)\n",
    "\n",
    "print(\"model selection finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 4 - Cross_Val Predictions for best model (RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.93      0.92       245\n",
      "           2       0.79      0.68      0.73        68\n",
      "           3       0.80      0.87      0.84        79\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       392\n",
      "   macro avg       0.84      0.83      0.83       392\n",
      "weighted avg       0.87      0.88      0.87       392\n",
      "\n",
      "    true / pred    USA (1) Europe (2)   Asia (3) \n",
      "       USA (1)      228.0       11.0        6.0 \n",
      "    Europe (2)       11.0       46.0       11.0 \n",
      "      Asia (3)        9.0        1.0       69.0 \n"
     ]
    }
   ],
   "source": [
    "kf = KFold(10, shuffle=True, random_state=1)\n",
    "\n",
    "best_model =  {'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', \n",
    "               'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1}\n",
    "model = RandomForestClassifier()\n",
    "model.set_params(**best_model)  \n",
    "\n",
    "predictions = cross_val_predict(model, df_clean[optimized_columns_RFC], target_df, cv=kf, )\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "print(classification_report(target_df, predictions))\n",
    "cm = confusion_matrix(target_df, predictions, labels=[1, 2, 3])\n",
    "myML_functions.print_cm(cm, labels=['USA (1)', 'Europe (2)', ' Asia (3)'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
