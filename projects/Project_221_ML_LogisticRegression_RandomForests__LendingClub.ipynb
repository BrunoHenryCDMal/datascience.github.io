{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: ML - Logistic Regression, Random Forests (Lending Club)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Problem:\n",
    "- Predict outcome of lending club loans to inform conservative investor from: stats on lenders & borrowers for approved and declined loan applications (loan amount, interest rate, employment length, income, installments)\n",
    "- Binary Classification (loan payed or defaulted) using LogisticRegression, KNNClassifier and RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Tools:\n",
    "\n",
    "- Feature Preparation, Selection and Engineering (transforming and processing):\n",
    "  - drop columns that leak information about the future, don't affect borrower's ability to pay the loan, need to be clean up, require a lot of processing, contain redundant information\n",
    "  - identify and clean the target colum (deal with inbalance in target with class_weight penalty)   \n",
    "  - identify numerical needing conversion   \n",
    "  - HMV: remove columns with more than 1% missing values, drop rows with missing values \n",
    "  - categorical features\n",
    "    - transform numerical to categorical (for those where numbers have no meaning)\n",
    "    - identify text columns to make categorical:\n",
    "      - only those with only a few unique values\n",
    "      - remove low varianve columns (more than 95% of the values are the same)\n",
    "    - deal with NaNs, then dummy code\n",
    "  - reshufle DF\n",
    "  - Feature Selection using RFECV\n",
    "- Models: Logistic Regression, KNN, Random Forest Classifier \n",
    "- Model validation and hyperparameter search: GridSearchCV, K-fold validation and predictions\n",
    "- Error Metrics: TPR and FPR, f1_score, recall_score, precision_score, accuracy and ROC_AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### load defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaults Loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import requests \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Math\n",
    "\n",
    "from functions import *\n",
    "\n",
    "plt.rcParams.update({'axes.titlepad': 20, 'font.size': 12, 'axes.titlesize':20})\n",
    "\n",
    "colors = [(0/255,107/255,164/255), (255/255, 128/255, 14/255), 'red', 'green', '#9E80BA', '#8EDB8E', '#58517A']\n",
    "Ncolors = 10\n",
    "color_map = plt.cm.Blues_r(np.linspace(0.2, 0.5, Ncolors))\n",
    "#color_map = plt.cm.tab20c_r(np.linspace(0.2, 0.5, Ncolors))\n",
    "\n",
    "\n",
    "#specific to this project\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_predict\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"Defaults Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Dataset: Lending Club stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>Ryder</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  1077501  1296599.0     5000.0       5000.0           4975.0   36 months   \n",
       "1  1077430  1314167.0     2500.0       2500.0           2500.0   60 months   \n",
       "2  1077175  1313524.0     2400.0       2400.0           2400.0   36 months   \n",
       "\n",
       "  int_rate  installment grade sub_grade emp_title emp_length home_ownership  \n",
       "0   10.65%       162.87     B        B2       NaN  10+ years           RENT  \n",
       "1   15.27%        59.83     C        C4     Ryder   < 1 year           RENT  \n",
       "2   15.96%        84.33     C        C5       NaN  10+ years           RENT  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Columns: 52\n"
     ]
    }
   ],
   "source": [
    "loans = pd.read_csv('./data/loans_2007.csv', low_memory=False)\n",
    "display(loans.iloc[:3,:13])\n",
    "print(\"Number of Columns: {:d}\".format(len(loans.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1-  Feature Preparation, Selection and Engineering:\n",
    "- identify and clean the target colum (lookout for class inbalance)\n",
    "- identify columns that:\n",
    "  - leak information about the future (after he loan was funded)\n",
    "  - don't affect the borrower's ability to pay back the loan\n",
    "  - formatted poorly and need to be clean up\n",
    "  - require more data or a lot of processing\n",
    "  - contain redundant information\n",
    "- drop columns with only one unique value (after removing nan)\n",
    "- handle missing values:\n",
    "  - remove columns with more than 1% missing values, keep employment length as it is likely a good predictor\n",
    "  - drop rows with missing values\n",
    "- identify numerical needing conversion and extraneous columns\n",
    "- dummy coding for categorical features\n",
    "  - transform numerical to categorical (for those where numbers have no meaning)\n",
    "  - identify text columns to make categorical:\n",
    "    - only those with only a few unique values\n",
    "    - remove low varianve columns (more than 95% of the values are the same)\n",
    "  - deal with NaNs, then dummy code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**target column**\n",
    "- loan_status is the only column that describes if the loan was paid in time, delayed or defaulted\n",
    "- it contains text values and needs to be converted to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Paid                                             33136\n",
      "Charged Off                                             5634\n",
      "Does not meet the credit policy. Status:Fully Paid      1988\n",
      "Current                                                  961\n",
      "Does not meet the credit policy. Status:Charged Off      761\n",
      "Late (31-120 days)                                        24\n",
      "In Grace Period                                           20\n",
      "Late (16-30 days)                                          8\n",
      "Default                                                    3\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(loans['loan_status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only fully paid and charged off characterize loans with a final outcome (the others are ongoing)\n",
    "- select only rows wih loan_status - fully paid or charged off\n",
    "- assign fully paid to 1 and charged of to 0, then we can have a binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    33136\n",
      "0     5634\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sel = (loans['loan_status']== 'Fully Paid') | (loans['loan_status']== 'Charged Off')\n",
    "loans = loans[sel]\n",
    "\n",
    "mapping_dict = {\n",
    "    \"loan_status\": {\n",
    "        \"Charged Off\": 0,\n",
    "        \"Fully Paid\": 1\n",
    "    }\n",
    "}\n",
    "loans = loans.replace(mapping_dict)\n",
    "print(loans['loan_status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**class inbalance in the target column**, keep in mind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "23\n",
      "emp_length              1036\n",
      "title                     11\n",
      "revol_util                50\n",
      "last_credit_pull_d         2\n",
      "pub_rec_bankruptcies     697\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop = ['id', 'member_id', 'funded_amnt', 'funded_amnt_inv', 'grade', 'sub_grade', 'emp_title', \n",
    "                'issue_d', 'zip_code', 'out_prncp', 'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', \n",
    "                'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries', \n",
    "                'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt']\n",
    "loans.drop(cols_to_drop, axis=1, inplace=True)\n",
    "print(len(loans.columns))\n",
    "\n",
    "\n",
    "#drop columns with only one unique value (after removing nan)\n",
    "drop_columns = []\n",
    "\n",
    "for element in loans.columns:\n",
    "    if(len(loans[element].dropna().unique())==1):\n",
    "        drop_columns.append(element)\n",
    "        \n",
    "loans.drop(drop_columns, axis=1, inplace=True)\n",
    "print(len(loans.columns))\n",
    "\n",
    "#remove columns with more than 1% missing values (keep employment length as it is likely a good predictor)\n",
    "null_counts = loans.isnull().sum()\n",
    "#print(null_counts[null_counts>len(loans)*0.01])\n",
    "print(null_counts[null_counts>0.])\n",
    "loans.drop('pub_rec_bankruptcies', axis=1, inplace=True)\n",
    "\n",
    "#drop rows with missing values\n",
    "loans.dropna(axis=0, inplace=True)\n",
    "null_counts = loans.isnull().sum()\n",
    "#print(null_counts[null_counts>0])\n",
    "\n",
    "#write file\n",
    "loans.to_csv('./data/filtered_loans_2007.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identify numerical needing conversion and extraneous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Verified</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>Computer</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Jan-1985</td>\n",
       "      <td>83.7%</td>\n",
       "      <td>Jun-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term int_rate emp_length home_ownership verification_status  \\\n",
       "0   36 months   10.65%  10+ years           RENT            Verified   \n",
       "\n",
       "       purpose     title addr_state earliest_cr_line revol_util  \\\n",
       "0  credit_card  Computer         AZ         Jan-1985      83.7%   \n",
       "\n",
       "  last_credit_pull_d  \n",
       "0           Jun-2016  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loans = pd.read_csv('./data/filtered_loans_2007.csv')\n",
    "object_columns_df = loans.select_dtypes(include=['object'])\n",
    "display(object_columns_df[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to numeric:\n",
    "loans['int_rate'] = loans['int_rate'].str.rstrip('%').astype(float)\n",
    "loans['revol_util'] = loans['revol_util'].str.rstrip('%').astype(float)\n",
    "\n",
    "#remove extraneous\n",
    "cols_to_drop = ['last_credit_pull_d', 'earliest_cr_line']\n",
    "loans.drop(cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dummy coding**:\n",
    "- home_ownership, verification_status, emp_length, term: few discrete values; encode as dummy\n",
    "- purpose, title: overlaping information; keep purpose since title contains 18881 discrete values\n",
    "- addr_state: 50 different values; remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "#cols = ['home_ownership', 'verification_status', 'emp_length', 'term', 'addr_state', 'purpose','title']\n",
    "\n",
    "#for element in cols:    \n",
    "#    print(len(object_columns_df[element].value_counts()))\n",
    "#    print(object_columns_df[element].value_counts()[:5])\n",
    "#    print('\\n')\n",
    "\n",
    "#drop 'addr_state' and 'title'\n",
    "cols_to_drop = ['addr_state', 'title']\n",
    "loans.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "#map emp_length\n",
    "mapping_dict = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "        \"n/a\": 0\n",
    "    }\n",
    "}\n",
    "loans = loans.replace(mapping_dict)\n",
    "\n",
    "#dummy code 'home_ownership', 'verification_status', 'purpose' and 'term'\n",
    "cols = ['home_ownership', 'verification_status', 'purpose', 'term']\n",
    "for element in cols:\n",
    "    loans[element] = loans[element].astype('category')\n",
    "\n",
    "dummy_df = pd.get_dummies(loans[cols])\n",
    "loans = pd.concat([loans, dummy_df], axis=1)\n",
    "loans.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "print(len(loans.columns))\n",
    "\n",
    "#Shuffle DF\n",
    "np.random.seed(1) \n",
    "loans = loans.iloc[np.random.permutation(len(loans))]\n",
    "\n",
    "#write file\n",
    "loans.to_csv('./data/cleaned_loans_2007.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2 - RFECV for Logistic Regression & Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = pd.read_csv('./data/cleaned_loans_2007.csv')\n",
    "\n",
    "feature_columns = loans.drop('loan_status', axis=1).columns.tolist()\n",
    "target = 'loan_status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Columns \n",
      "------------\n",
      "['loan_amnt', 'int_rate', 'installment', 'annual_inc', 'dti', 'open_acc', 'revol_bal', 'revol_util', 'total_acc', 'term_ 60 months']\n",
      "\n",
      "Best Columns \n",
      "------------\n",
      "['term_ 36 months']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def select_features(df, target, model):    \n",
    "    #select numeric and drop NaNs\n",
    "    df_new = df.select_dtypes([np.number]).dropna(axis=1)\n",
    "    #drop survived and ID\n",
    "    all_X = df_new.drop(target,axis=1)\n",
    "    all_y = df_new[target]\n",
    "        \n",
    "    #cv is the number of folds\n",
    "    selector = RFECV(model, cv=10)\n",
    "    selector.fit(all_X, all_y)  \n",
    "    optimized_columns = list(all_X.columns[selector.support_])\n",
    "    \n",
    "    print(\"Best Columns \\n\"+\"-\"*12+\"\\n{}\\n\".format(optimized_columns))    \n",
    "    return optimized_columns\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50, random_state=1, min_samples_leaf=5, class_weight='balanced')\n",
    "optimized_columns_RFC = select_features(loans[:int(len(loans)/5.)], target, model)\n",
    "\n",
    "model = LogisticRegression(solver = 'lbfgs', class_weight='balanced', max_iter=3000)\n",
    "optimized_columns_LR = select_features(loans[:int(len(loans)/5.)], target, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3 - Model Selection with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "------------------\n",
      "ROC_AUC: 0.615\n",
      "Accuracy: 0.853\n",
      "precision_1: 0.891\n",
      "recall_1: 1.000\n",
      "f1_1: 0.920\n",
      "precision_0: 0.262\n",
      "recall_0: 0.447\n",
      "f1_0: 0.330\n",
      "Best Parameters: {'class_weight': 'balanced', 'solver': 'newton-cg'}\n",
      "Best Score: 0.615\n",
      "\n",
      "\n",
      "KNeighborsClassifier\n",
      "--------------------\n",
      "ROC_AUC: 0.615\n",
      "Accuracy: 0.853\n",
      "precision_1: 0.864\n",
      "recall_1: 1.000\n",
      "f1_1: 0.920\n",
      "precision_0: 0.076\n",
      "recall_0: 0.134\n",
      "f1_0: 0.097\n",
      "Best Parameters: {'algorithm': 'brute', 'n_neighbors': 19, 'p': 1, 'weights': 'distance'}\n",
      "Best Score: 0.615\n",
      "\n",
      "\n",
      "RandomForestClassifier\n",
      "----------------------\n",
      "ROC_AUC: 0.699\n",
      "Accuracy: 0.854\n",
      "precision_1: 0.909\n",
      "recall_1: 1.000\n",
      "f1_1: 0.921\n",
      "precision_0: 0.588\n",
      "recall_0: 0.591\n",
      "f1_0: 0.364\n",
      "Best Parameters: {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 20}\n",
      "Best Score: 0.699\n",
      "\n",
      "\n",
      "model selection finished\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)\n",
    "\n",
    "def select_model(df, features_list, target, models_to_fit):    \n",
    "    \n",
    "    dicts= [ {\n",
    "               \"name\": \"LogisticRegression\",\n",
    "               \"estimator\": LogisticRegression(max_iter = 5000),\n",
    "               \"hyperparameters\": \n",
    "                 {                \n",
    "                   \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"],  \n",
    "                   \"class_weight\": [\"balanced\", \"\"]                      \n",
    "                 }\n",
    "             },\n",
    "             {\n",
    "               \"name\": \"KNeighborsClassifier\",\n",
    "               \"estimator\": KNeighborsClassifier(),\n",
    "               \"hyperparameters\": \n",
    "                 {\n",
    "                   \"n_neighbors\": range(1,20,2),\n",
    "                   \"weights\": [\"distance\", \"uniform\"],\n",
    "                   \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "                   \"p\": [1,2]\n",
    "                 }\n",
    "             },\n",
    "             {\n",
    "               \"name\": \"RandomForestClassifier\",\n",
    "               \"estimator\": RandomForestClassifier(),\n",
    "               \"hyperparameters\": \n",
    "                 {\n",
    "                   \"n_estimators\": [5, 20, 100],\n",
    "                   \"criterion\": [\"entropy\", \"gini\"],\n",
    "                   \"max_depth\": [2, 5, 10],\n",
    "                   \"max_features\": [\"log2\", \"sqrt\"],\n",
    "                   \"min_samples_leaf\": [1, 5, 8],\n",
    "                   \"min_samples_split\": [2, 3, 5], \n",
    "                   \"class_weight\": [None, \"balanced\", {0: 3, 1: 1}, {0: 5, 1: 1}]               \n",
    "                 }\n",
    "             } ]    \n",
    "    \n",
    "    scoring = {'ROC_AUC':'roc_auc', 'Accuracy':'accuracy', \n",
    "               'precision_1': make_scorer(precision_score, pos_label=1),\n",
    "               'recall_1': make_scorer(recall_score, pos_label=1),\n",
    "               'f1_1': make_scorer(f1_score, pos_label=1),\n",
    "               'precision_0': make_scorer(precision_score, pos_label=0),\n",
    "               'recall_0': make_scorer(recall_score, pos_label=0),\n",
    "               'f1_0': make_scorer(f1_score, pos_label=0)}\n",
    "    \n",
    "    all_y = df[target]\n",
    "    for element in dicts:\n",
    "        if(element['name'] not in models_to_fit):\n",
    "            continue\n",
    "        print(element['name'])\n",
    "        print('-'*len(element['name']))\n",
    "        \n",
    "        all_X = df[features_list[element['name']]]\n",
    "        model = element['estimator']\n",
    "        grid = GridSearchCV(model, element['hyperparameters'], cv=10, scoring=scoring, refit='ROC_AUC', iid=True)\n",
    "        grid.fit(all_X, all_y)\n",
    "        \n",
    "        element['best_params'] = grid.best_params_\n",
    "        element['best_score'] = grid.best_score_\n",
    "        element['best_estimator'] = grid.best_estimator_          \n",
    "        for scorer in scoring:          \n",
    "            print(f\"{scorer}: {max(grid.cv_results_['mean_test_'+scorer]):0.3f}\")\n",
    "        print(\"Best Parameters: {}\".format(grid.best_params_))\n",
    "        print(\"Best Score: {:0.3f}\\n\\n\".format(grid.best_score_))\n",
    "        \n",
    "        \n",
    "        #for scorer in scoring:\n",
    "        #    print(cv_results_'_<scorer_name>')\n",
    "       \n",
    "    return dicts\n",
    "        \n",
    "models_to_fit = ['LogisticRegression','KNeighborsClassifier','RandomForestClassifier']\n",
    "optimized_columns = {'LogisticRegression': optimized_columns_LR, \n",
    "                     'KNeighborsClassifier': optimized_columns_LR, \n",
    "                     'RandomForestClassifier': optimized_columns_RFC}\n",
    " \n",
    "model_dicts = select_model(loans[:int(len(loans)/10.)], optimized_columns, target, models_to_fit)\n",
    "\n",
    "\n",
    "print(\"model selection finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 4 - Cross_Val Predictions for best model (RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.64      0.33      5389\n",
      "           1       0.91      0.63      0.75     32286\n",
      "\n",
      "   micro avg       0.63      0.63      0.63     37675\n",
      "   macro avg       0.57      0.63      0.54     37675\n",
      "weighted avg       0.81      0.63      0.69     37675\n",
      "\n",
      "[[ 3435  1954]\n",
      " [11878 20408]]\n",
      "TPR:0.224, FPR:0.087\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(10, shuffle=True, random_state=1)\n",
    "\n",
    "best_model =  {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', \n",
    "               'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 20}\n",
    "model = RandomForestClassifier()\n",
    "model.set_params(**best_model)  \n",
    "\n",
    "predictions = cross_val_predict(model, loans[optimized_columns_RFC], loans[target], cv=kf, )\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "#classification report\n",
    "print(classification_report(loans[target],predictions))\n",
    "\n",
    "c_matrix = confusion_matrix(loans[target],predictions)\n",
    "print(c_matrix)\n",
    "tp = c_matrix[0][0]\n",
    "fp = c_matrix[0][1]\n",
    "fn = c_matrix[1][0]\n",
    "tn = c_matrix[1][1]\n",
    "\n",
    "tpr = tp/(tp+fn)\n",
    "fpr = fp/(fp+tn)\n",
    "\n",
    "print(\"TPR:{:0.3f}, FPR:{:0.3f}\".format(tpr, fpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 5 - Logistic Regression Model with different weights\n",
    "- good first model for binary classification problems:\n",
    "  - quick to train and we can iterate more quickly\n",
    "  - less prone to overfitting than more complex models like decision trees\n",
    "  - easy to interpret\n",
    "- **Error Metric**\n",
    "  - In this problem we are mostly concerned with false positives (cost money) and false negatives (loose potential money)\n",
    "  - because of class inbalance a classifier can predict one for every row and still have high accuracy, use false positives and negatives\n",
    "  - optimize for high recall (true positive rate) and low fall-out (false positive rate):\n",
    "  - $TPR=\\frac{\\mathrm{True Positives}}{\\mathrm{True Positives+False Negatives}}$\n",
    "  - $FPR=\\frac{\\mathrm{False Positives}}{\\mathrm{False Positives+True Negatives}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model with kfold predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR:0.999, FPR:0.997\n"
     ]
    }
   ],
   "source": [
    "loans = pd.read_csv('./data/cleaned_loans_2007.csv')\n",
    "\n",
    "features_df = loans.drop('loan_status', axis=1)\n",
    "target = 'loan_status'\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=30000)\n",
    "kf = KFold(10, random_state=1)\n",
    "\n",
    "predictions = cross_val_predict(lr, features_df, loans[target], cv=kf)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tp = len(predictions[(loans[target]==1) & (predictions==1)])\n",
    "tn = len(predictions[(loans[target]==0) & (predictions==0)])\n",
    "fp = len(predictions[(loans[target]==0) & (predictions==1)])\n",
    "fn = len(predictions[(loans[target]==1) & (predictions==0)])\n",
    "\n",
    "tpr = tp/(tp+fn)\n",
    "fpr = fp/(fp+tn)\n",
    "\n",
    "print(\"TPR:{:0.3f}, FPR:{:0.3f}\".format(tpr, fpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model with class_weight='balanced'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**correct for inbalance** by penalizing misclassifications of the less prevalent class more than the other class:\n",
    "- class_weight='balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR:0.540, FPR:0.334\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=3000)\n",
    "#cross validation accross all the rows of the training data (kfold=n, leave one out validation)\n",
    "#kf = KFold(features.shape[0], random_state=1)\n",
    "kf = KFold(10, random_state=1)\n",
    "predictions = cross_val_predict(lr, features_df, loans[target], cv=kf, )\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tp = len(predictions[(loans[target]==1) & (predictions==1)])\n",
    "tn = len(predictions[(loans[target]==0) & (predictions==0)])\n",
    "fp = len(predictions[(loans[target]==0) & (predictions==1)])\n",
    "fn = len(predictions[(loans[target]==1) & (predictions==0)])\n",
    "\n",
    "tpr = tp/(tp+fn)\n",
    "fpr = fp/(fp+tn)\n",
    "\n",
    "print(\"TPR:{:0.3f}, FPR:{:0.3f}\".format(tpr, fpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model with class_weight=penalty dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting class_wight to balanced assign a penalty of ~5.89 for misclassifying 0 (there as 5.89 times more 1's than 0's)\n",
    "- we can **set the penalty manually** to try to lower the false positive rates (higher penalty for misclassifying the negative class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR:0.162, FPR:0.067\n"
     ]
    }
   ],
   "source": [
    "penalty = {0: 10, 1: 1}\n",
    "lr = LogisticRegression(solver = 'lbfgs', class_weight=penalty, max_iter=3000)\n",
    "#kf = KFold(features.shape[0], random_state=1)\n",
    "kf = KFold(10, random_state=1)\n",
    "predictions = cross_val_predict(lr, features_df, loans[target], cv=kf, )\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tp = len(predictions[(loans[target]==1) & (predictions==1)])\n",
    "tn = len(predictions[(loans[target]==0) & (predictions==0)])\n",
    "fp = len(predictions[(loans[target]==0) & (predictions==1)])\n",
    "fn = len(predictions[(loans[target]==1) & (predictions==0)])\n",
    "\n",
    "tpr = tp/(tp+fn)\n",
    "fpr = fp/(fp+tn)\n",
    "\n",
    "print(\"TPR:{:0.3f}, FPR:{:0.3f}\".format(tpr, fpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lower false positive rate at the expense of true positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
