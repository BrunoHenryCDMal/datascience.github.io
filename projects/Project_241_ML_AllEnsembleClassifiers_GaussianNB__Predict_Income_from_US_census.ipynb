{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: ML - All Ensemble Classifiers + GaussianNB & KNN (Predict Income from US census)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Problem:\n",
    "- Predict if someone has high income or not from US census data: age, education, sex, race, occupation, etc\n",
    "- Binary classification using all types of ensemble classifiers from sklearn + GaussianNB and KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Tools:\n",
    "- Feature Engineering: transform variables to categorical and reshuffle df, RFECV \n",
    "- Models: BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier, GaussianNB, DecisionTreeClassifier, LogisticRegression, KNeighborsClassifier\n",
    "- Model validation and hyperparameter search: GridSearchCV\n",
    "- Error Metrics: ROC_AUC, precision, recall, f1, classification_report & confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### load defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaults Loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import requests \n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Math\n",
    "\n",
    "from functions import *\n",
    "import myML_functions as myML_functions\n",
    "\n",
    "plt.rcParams.update({'axes.titlepad': 20, 'font.size': 12, 'axes.titlesize':20})\n",
    "\n",
    "colors = [(0/255,107/255,164/255), (255/255, 128/255, 14/255), 'red', 'green', '#9E80BA', '#8EDB8E', '#58517A']\n",
    "Ncolors = 10\n",
    "color_map = plt.cm.Blues_r(np.linspace(0.2, 0.5, Ncolors))\n",
    "#color_map = plt.cm.tab20c_r(np.linspace(0.2, 0.5, Ncolors))\n",
    "\n",
    "\n",
    "#specific to this project\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_predict\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "\n",
    "print(\"Defaults Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Dataset: US census, predict high or low income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>high_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education_num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "\n",
       "        marital_status        occupation    relationship    race    sex  \\\n",
       "0        Never-married      Adm-clerical   Not-in-family   White   Male   \n",
       "1   Married-civ-spouse   Exec-managerial         Husband   White   Male   \n",
       "\n",
       "   capital_gain  capital_loss high_income  \n",
       "0          2174             0       <=50K  \n",
       "1             0             0       <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set index_col to False to avoid pandas thinking that the first column is row indexes (it's age)\n",
    "income = pd.read_csv(\"./data/income.csv\", index_col=False)\n",
    "display(income.iloc[:2,[0,1,2,3,4,5,6,7,8,9,10,11,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>high_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  education  education_num  marital_status  occupation  \\\n",
       "0   39          7          9             13               4           1   \n",
       "1   50          6          9             13               2           4   \n",
       "2   38          4         11              9               0           6   \n",
       "\n",
       "   relationship  race  sex  hours_per_week  native_country  high_income  \n",
       "0             1     4    1              40              39            0  \n",
       "1             0     4    1              13              39            0  \n",
       "2             1     4    1              40              39            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert text categories to numbers\n",
    "cols = ['workclass', 'education', 'marital_status', 'occupation', \n",
    "        'relationship', 'race', 'sex', 'native_country', 'high_income']\n",
    "\n",
    "for element in cols:\n",
    "    #col = pandas.Categorical.from_array(income[element])\n",
    "    col = pd.Categorical(income[element])\n",
    "    income[element] = col.codes\n",
    "\n",
    "#remove columns without interesting infomration information\n",
    "income.drop(['fnlwgt', 'capital_gain', 'capital_loss'], axis=1, inplace=True)\n",
    "display(income[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns to train with (all have been converted to numeric)\n",
    "all_columns = [\"age\", \"workclass\", \"education\", \"education_num\", \"marital_status\", \"occupation\", \n",
    "           \"relationship\", \"race\", \"sex\", \"hours_per_week\", \"native_country\"]\n",
    "target = 'high_income'\n",
    "\n",
    "# Shuffle the rows  \n",
    "np.random.seed(1)\n",
    "income = income.reindex(np.random.permutation(income.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1 - Decision Tree Classifier with holdout validation to check for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC train:0.947, AUC test:0.694\n"
     ]
    }
   ],
   "source": [
    "#create train and test set for holdout validation\n",
    "train = income[0:int(len(income)*0.8)]\n",
    "test = income[int(len(income)*0.8):]\n",
    "\n",
    "# Instantiate the classifier (Set random_state to 1 to be able to replicate)\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "clf.fit(train[all_columns], train[\"high_income\"])\n",
    "\n",
    "predictions = clf.predict(test[all_columns])\n",
    "test_auc = roc_auc_score(test['high_income'], predictions)\n",
    "\n",
    "predictions = clf.predict(train[all_columns])\n",
    "train_auc = roc_auc_score(train['high_income'], predictions)\n",
    "print(\"AUC train:{:0.3f}, AUC test:{:0.3f}\".format(train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions on train set are significantly better, hint of **overfitting**. To avoid overfittin restrict max_depth and min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC train:0.748, AUC test:0.744\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=1, max_depth=7, min_samples_split=13)\n",
    "clf.fit(train[all_columns], train[\"high_income\"])\n",
    "predictions = clf.predict(test[all_columns])\n",
    "test_auc = roc_auc_score(test[\"high_income\"], predictions)\n",
    "\n",
    "train_predictions = clf.predict(train[all_columns])\n",
    "train_auc = roc_auc_score(train[\"high_income\"], train_predictions)\n",
    "\n",
    "print(\"AUC train:{:0.3f}, AUC test:{:0.3f}\".format(train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2 - cross_val_predict Decision Tree Classifier & Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.72      0.82     24720\n",
      "           1       0.50      0.85      0.63      7841\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     32561\n",
      "   macro avg       0.72      0.79      0.72     32561\n",
      "weighted avg       0.83      0.76      0.77     32561\n",
      "\n",
      "    true / pred  Low Income High Income \n",
      "     Low Income     17908.0      6812.0 \n",
      "    High Income      1148.0      6693.0 \n",
      "\n",
      "ROC_AUC: 0.789\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(10, shuffle=True, random_state=1)\n",
    "\n",
    "best_model =  {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', \n",
    "               'min_samples_leaf': 5, 'min_samples_split': 13, 'random_state':1}\n",
    "model = DecisionTreeClassifier()\n",
    "model.set_params(**best_model)  \n",
    "\n",
    "predictions = cross_val_predict(model, income[all_columns], income[target], cv=kf, )\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "print(classification_report(income[target],predictions))\n",
    "cm = confusion_matrix(income[target],predictions)\n",
    "myML_functions.print_cm(cm, labels=['Low Income', 'High Income'])\n",
    "print(f\"\\nROC_AUC: {roc_auc_score(income[target], predictions):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.71      0.81     24720\n",
      "           1       0.49      0.88      0.63      7841\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     32561\n",
      "   macro avg       0.72      0.80      0.72     32561\n",
      "weighted avg       0.84      0.75      0.77     32561\n",
      "\n",
      "    true / pred  Low Income High Income \n",
      "     Low Income     17631.0      7089.0 \n",
      "    High Income       939.0      6902.0 \n",
      "\n",
      "ROC_AUC: 0.797\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(10, shuffle=True, random_state=1)\n",
    "\n",
    "best_model =  {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', \n",
    "               'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 150, 'n_jobs': -1, 'random_state':1}\n",
    "model = RandomForestClassifier()\n",
    "model.set_params(**best_model)  \n",
    "\n",
    "predictions = cross_val_predict(model, income[all_columns], income[target], cv=kf, )\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "print(classification_report(income[target],predictions))\n",
    "cm = confusion_matrix(income[target],predictions)\n",
    "myML_functions.print_cm(cm, labels=['Low Income', 'High Income'])\n",
    "print(f\"\\nROC_AUC: {roc_auc_score(income[target], predictions):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3 - RFECV for Decision Tree & Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Columns, RandomForestClassifier model: ['age', 'education', 'education_num', 'marital_status', 'relationship', 'hours_per_week']\n",
      "\n",
      "----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def select_features(df, target, model):    \n",
    "    #select numeric and drop NaNs\n",
    "    df_new = df.select_dtypes([np.number]).dropna(axis=1)\n",
    "  \n",
    "    all_X = df_new.drop(target, axis=1)\n",
    "    all_y = df_new[target]\n",
    "    \n",
    "    #cv is the number of folds\n",
    "    selector = RFECV(model, cv=10)\n",
    "    selector.fit(all_X, all_y)    \n",
    "    optimized_columns = list(all_X.columns[selector.support_])\n",
    "    \n",
    "    print(f\"Best Columns, {type(model).__name__} model: {optimized_columns}\\n\")          \n",
    "    print('----------------------------------------------------\\n')      \n",
    "    \n",
    "    return optimized_columns\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=150, random_state=1, min_samples_leaf=5, min_samples_split=2,\n",
    "                               max_depth=5, max_features='auto', class_weight='balanced', n_jobs=-1)\n",
    "opt_cols_RFC = select_features(income, target, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_manual = [\"age\", \"workclass\", \"education\", \"education_num\", \"marital_status\", \"occupation\", \n",
    "                            \"relationship\", \"race\", \"sex\", \"hours_per_week\", \"native_country\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 4 - Model Selection with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples to train on: 3256\n",
      "\n",
      "VotingClassifier\n",
      "----------------\n",
      "ROC_AUC:0.863 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "Accuracy:       0.807 | 0.807\n",
      "recall:         0.807 | 0.807\n",
      "recall_1:       0.695 | 0.695\n",
      "recall_0:       0.840 | 0.840\n",
      "\n",
      "Best Parameters: {'voting': 'soft'}\n",
      "Best Score: 0.863\n",
      "\n",
      "Time elapsed: 0.29 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "LogisticRegression\n",
      "------------------\n",
      "ROC_AUC:0.814 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "Accuracy:       0.808 | 0.727\n",
      "recall:         0.808 | 0.727\n",
      "recall_1:       0.765 | 0.764\n",
      "recall_0:       0.946 | 0.717\n",
      "\n",
      "Best Parameters: {'class_weight': 'balanced', 'solver': 'newton-cg'}\n",
      "Best Score: 0.814\n",
      "\n",
      "Time elapsed: 0.05 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "GaussianNB\n",
      "----------\n",
      "ROC_AUC:0.848 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "Accuracy:       0.807 | 0.807\n",
      "recall:         0.807 | 0.807\n",
      "recall_1:       0.670 | 0.670\n",
      "recall_0:       0.847 | 0.847\n",
      "\n",
      "Best Parameters: {'var_smoothing': 1e-08}\n",
      "Best Score: 0.848\n",
      "\n",
      "Time elapsed: 0.02 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "KNeighborsClassifier\n",
      "--------------------\n",
      "ROC_AUC:0.838 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "Accuracy:       0.817 | 0.811\n",
      "recall:         0.817 | 0.811\n",
      "recall_1:       0.491 | 0.455\n",
      "recall_0:       0.919 | 0.915\n",
      "\n",
      "Best Parameters: {'algorithm': 'brute', 'n_neighbors': 19, 'p': 1, 'weights': 'uniform'}\n",
      "Best Score: 0.838\n",
      "\n",
      "Time elapsed: 13.06 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "BaggingClassifier\n",
      "-----------------\n",
      "ROC_AUC:0.869 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "Accuracy:       0.822 | 0.781\n",
      "recall:         0.822 | 0.781\n",
      "recall_1:       0.382 | 0.042\n",
      "recall_0:       1.000 | 0.999\n",
      "\n",
      "Best Parameters: {'bootstrap': False, 'max_features': 0.1, 'max_samples': 0.5, 'n_estimators': 100, 'warm_start': False}\n",
      "Best Score: 0.869\n",
      "\n",
      "Time elapsed: 45.20 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "GradientBoostingClassifier\n",
      "--------------------------\n",
      "ROC_AUC:0.869 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "Accuracy:       0.826 | 0.823\n",
      "recall:         0.826 | 0.823\n",
      "recall_1:       0.509 | 0.438\n",
      "recall_0:       1.000 | 0.936\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.05, 'max_features': 'log2', 'n_estimators': 100, 'random_state': 1, 'subsample': 1.0}\n",
      "Best Score: 0.869\n",
      "\n",
      "Time elapsed: 1.40 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "AdaBoostClassifier\n",
      "------------------\n",
      "ROC_AUC:0.868 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "Accuracy:       0.822 | 0.822\n",
      "recall:         0.822 | 0.822\n",
      "recall_1:       0.445 | 0.357\n",
      "recall_0:       1.000 | 0.959\n",
      "\n",
      "Best Parameters: {'algorithm': 'SAMME.R', 'learning_rate': 0.1, 'n_estimators': 100, 'random_state': 1}\n",
      "Best Score: 0.868\n",
      "\n",
      "Time elapsed: 0.57 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "DecisionTreeClassifier\n",
      "----------------------\n",
      "ROC_AUC:0.855 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "Accuracy:       0.821 | 0.754\n",
      "recall:         0.821 | 0.754\n",
      "recall_1:       0.877 | 0.839\n",
      "recall_0:       0.994 | 0.729\n",
      "\n",
      "Best Parameters: {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 19, 'min_samples_split': 2}\n",
      "Best Score: 0.855\n",
      "\n",
      "Time elapsed: 3.34 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "ExtraTreesClassifier\n",
      "--------------------\n",
      "ROC_AUC:0.868 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "Accuracy:       0.826 | 0.743\n",
      "recall:         0.826 | 0.743\n",
      "recall_1:       0.969 | 0.863\n",
      "recall_0:       1.000 | 0.708\n",
      "\n",
      "Best Parameters: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 20}\n",
      "Best Score: 0.868\n",
      "\n",
      "Time elapsed: 27.07 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "RandomForestClassifier\n",
      "----------------------\n",
      "ROC_AUC:0.868 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "Accuracy:       0.826 | 0.822\n",
      "recall:         0.826 | 0.822\n",
      "recall_1:       0.924 | 0.405\n",
      "recall_0:       0.991 | 0.944\n",
      "\n",
      "Best Parameters: {'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Score: 0.868\n",
      "\n",
      "Time elapsed: 30.04 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "model selection finished\n"
     ]
    }
   ],
   "source": [
    "def select_model(df, target, models_to_fit, refit_metric = 'ROC_AUC'): \n",
    "    \n",
    "    lr = LogisticRegression(max_iter = 50000, solver='newton')\n",
    "    rf = RandomForestClassifier(n_estimators=150, random_state=1, min_samples_leaf=5, min_samples_split=2,\n",
    "                                max_depth=5, max_features='auto', class_weight='balanced') \n",
    "    gnb = GaussianNB()\n",
    "    gb = GradientBoostingClassifier(n_estimators=150, random_state=1, min_samples_leaf=5, min_samples_split=2,\n",
    "                                    max_depth=5, max_features='auto')\n",
    "    ab = AdaBoostClassifier(n_estimators=150, random_state=1, learning_rate=0.5, algorithm='SAMME.R')\n",
    "    \n",
    "    dicts= [ {\n",
    "               \"name\": \"LogisticRegression\",\n",
    "               \"estimator\": LogisticRegression(max_iter = 50000),\n",
    "               \"hyperparameters\": \n",
    "                 {                \n",
    "                   \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"],  \n",
    "                   \"class_weight\": [\"balanced\", \"\"]                      \n",
    "                 }\n",
    "             },\n",
    "             {\n",
    "               \"name\": \"GaussianNB\",\n",
    "               \"estimator\": GaussianNB(),\n",
    "               \"hyperparameters\": \n",
    "                 {                   \n",
    "                   \"var_smoothing\": [1.e-8,1.e-9,1.e-10]                      \n",
    "                 }\n",
    "             },\n",
    "             {\n",
    "               \"name\": \"KNeighborsClassifier\",\n",
    "               \"estimator\": KNeighborsClassifier(),\n",
    "               \"hyperparameters\": \n",
    "                 {\n",
    "                   \"n_neighbors\": range(1,20,2),\n",
    "                   \"weights\": [\"distance\", \"uniform\"],\n",
    "                   \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "                   \"p\": [1,2]\n",
    "                 }\n",
    "             },\n",
    "             {\n",
    "               \"name\": \"BaggingClassifier\",\n",
    "               \"estimator\": BaggingClassifier(KNeighborsClassifier(algorithm='kd_tree', n_neighbors=13, \n",
    "                                                                   p=2, weights='uniform')),\n",
    "               \"hyperparameters\": \n",
    "                 {\n",
    "                   \"n_estimators\": [5, 20, 100],  \n",
    "                   \"max_samples\" :[0.1, 0.5, 0.8],\n",
    "                   \"max_features\" :[0.1, 0.5, 0.8],   \n",
    "                   \"bootstrap\" :[True, False],\n",
    "                   \"warm_start\" :[True, False]\n",
    "                 }\n",
    "             },\n",
    "             {\n",
    "               \"name\": \"GradientBoostingClassifier\",\n",
    "               \"estimator\": GradientBoostingClassifier(),\n",
    "               \"hyperparameters\": \n",
    "                 {\n",
    "                   \"n_estimators\": [5, 20, 100],  \n",
    "                   \"max_features\": [\"auto\", \"log2\", \"sqrt\"],\n",
    "                   \"learning_rate\":[0.01, 0.05, 0.1, 0.5],\n",
    "                   \"subsample\":[0.1, 0.5, 1.0],  \n",
    "                   \"random_state\":[1]     \n",
    "                 }\n",
    "             },\n",
    "             {\n",
    "               \"name\": \"AdaBoostClassifier\",\n",
    "               \"estimator\": AdaBoostClassifier(),\n",
    "               \"hyperparameters\": \n",
    "                 {\n",
    "                   \"n_estimators\": [5, 20, 100],                     \n",
    "                   \"learning_rate\":[0.01, 0.05, 0.1, 0.5],\n",
    "                   \"algorithm\": ['SAMME','SAMME.R'],  \n",
    "                   \"random_state\":[1]     \n",
    "                 }\n",
    "             },\n",
    "             {\n",
    "               \"name\": \"DecisionTreeClassifier\",\n",
    "               \"estimator\": DecisionTreeClassifier(),\n",
    "               \"hyperparameters\": \n",
    "                 {                   \n",
    "                   \"criterion\": [\"entropy\", \"gini\"],\n",
    "                   \"max_depth\": [2, 5, 10],\n",
    "                   \"max_features\": [\"log2\", \"sqrt\"],\n",
    "                   \"min_samples_leaf\": range(1,20,3),\n",
    "                   \"min_samples_split\": range(2,20,3), \n",
    "                   \"class_weight\": [None, \"balanced\"]               \n",
    "                 }\n",
    "             },\n",
    "             {\n",
    "               \"name\": \"ExtraTreesClassifier\",\n",
    "               \"estimator\": ExtraTreesClassifier(),\n",
    "               \"hyperparameters\": \n",
    "                 {     \n",
    "                   \"n_estimators\": [5, 20, 100],  \n",
    "                   \"criterion\": [\"entropy\", \"gini\"],\n",
    "                   \"max_depth\": [2, 5, 10],\n",
    "                   \"max_features\": [\"log2\", \"sqrt\"],\n",
    "                   \"min_samples_leaf\": [1, 5, 8],\n",
    "                   \"min_samples_split\": [2, 3, 5], \n",
    "                   \"class_weight\": [None, \"balanced\", {0: 1, 1: 3}, {0: 1, 1: 5}]               \n",
    "                 }\n",
    "             },\n",
    "             {\n",
    "               \"name\": \"RandomForestClassifier\",\n",
    "               \"estimator\": RandomForestClassifier(),\n",
    "               \"hyperparameters\": \n",
    "                 {     \n",
    "                   \"n_estimators\": [5, 20, 100],  \n",
    "                   \"criterion\": [\"entropy\", \"gini\"],\n",
    "                   \"max_depth\": [2, 5, 10],\n",
    "                   \"max_features\": [\"log2\", \"sqrt\"],\n",
    "                   \"min_samples_leaf\": [1, 5, 8],\n",
    "                   \"min_samples_split\": [2, 3, 5], \n",
    "                   \"class_weight\": [None, \"balanced\", {0: 1, 1: 3}, {0: 1, 1: 5}]               \n",
    "                 }\n",
    "             },\n",
    "             {\n",
    "               \"name\": \"VotingClassifier\",\n",
    "               \"estimator\": VotingClassifier(estimators=[('rf', rf), ('gb', gb), ('ab', ab)]),              \n",
    "               \"hyperparameters\": \n",
    "                 {     \n",
    "                   \"voting\": [\"soft\"]           \n",
    "                 }\n",
    "                \n",
    "             }]    \n",
    "  \n",
    "    scoring = {'ROC_AUC':'roc_auc', 'Accuracy':'accuracy', \n",
    "               'recall': make_scorer(recall_score, average='weighted'),\n",
    "               'recall_1': make_scorer(recall_score, pos_label=1),              \n",
    "               'recall_0': make_scorer(recall_score, pos_label=0)}\n",
    "        \n",
    "    all_y = df[target]    \n",
    "    for key, models_list in models_to_fit.items():        \n",
    "        print(key)\n",
    "        print('-'*len(key))\n",
    "        start = time.time()\n",
    "        for element in dicts:\n",
    "            if models_list[0] == element['name']:               \n",
    "                all_X = df[models_list[1]]   \n",
    "                model = element['estimator']                \n",
    "                grid = GridSearchCV(model, element['hyperparameters'], cv=10, scoring=scoring, \n",
    "                                    refit=refit_metric, iid=True, n_jobs=1)\n",
    "                grid.fit(all_X, all_y)\n",
    "                \n",
    "                element['best_params'] = grid.best_params_\n",
    "                element['best_score'] = grid.best_score_\n",
    "                element['best_estimator'] = grid.best_estimator_  \n",
    "                \n",
    "                #get the index of the best model in the list of scores\n",
    "                results = grid.cv_results_\n",
    "                best_index = np.nonzero(results['rank_test_%s' % refit_metric] == 1)[0][0]\n",
    "                \n",
    "                #print best score for Metric used to choose best model\n",
    "                print(f\"{refit_metric}:{max(results['mean_test_'+refit_metric]):0.3f} \", end=\"\")\n",
    "                print(f\"(Metric used to choose best model)\\n\") \n",
    "                \n",
    "                #loop over the scores for all metrics for all models\n",
    "                print(f\"{' ':10} best_value | value_best_model\")\n",
    "                for scorer in scoring:   \n",
    "                    #print scores for other metrics \n",
    "                    if(scorer!=refit_metric):                                                 \n",
    "                        score_best_model = results['mean_test_%s' % scorer][best_index]\n",
    "                        print(f\"{scorer+':':<15} {max(results['mean_test_'+scorer]):0.3f} | {score_best_model:0.3f}\")\n",
    "                print(\"\")       \n",
    "                print(f\"Best Parameters: {grid.best_params_}\")\n",
    "                print(f\"Best Score: {grid.best_score_:0.3f}\\n\")\n",
    "        \n",
    "        print(f\"Time elapsed: {(time.time()-start)/60.:0.2f} mins\\n\")\n",
    "        print(\"=\"*110)\n",
    "        print(\"\\n\")\n",
    "        #for scorer in scoring:\n",
    "        #    print(cv_results_'_<scorer_name>')\n",
    "       \n",
    "    return dicts\n",
    " \n",
    "models_to_fit = {'VotingClassifier': ['VotingClassifier', opt_cols_RFC],\n",
    "                 'LogisticRegression': ['LogisticRegression', opt_cols_RFC], \n",
    "                 'GaussianNB': ['GaussianNB', opt_cols_RFC], \n",
    "                 'KNeighborsClassifier': ['KNeighborsClassifier', opt_cols_RFC],\n",
    "                 'BaggingClassifier': ['BaggingClassifier', opt_cols_RFC],                 \n",
    "                 'GradientBoostingClassifier': ['GradientBoostingClassifier', opt_cols_RFC],\n",
    "                 'AdaBoostClassifier': ['AdaBoostClassifier', opt_cols_RFC],\n",
    "                 'DecisionTreeClassifier': ['DecisionTreeClassifier', opt_cols_RFC],\n",
    "                 'ExtraTreesClassifier': ['ExtraTreesClassifier', opt_cols_RFC],                \n",
    "                 'RandomForestClassifier': ['RandomForestClassifier', opt_cols_RFC]\n",
    "                 \n",
    "                }    \n",
    "                         \n",
    "#models_to_fit = {'DecisionTreeClassifier': ['DecisionTreeClassifier', opt_cols_RFC]} \n",
    "                  \n",
    "max_train_row = int(len(income)*0.1)     \n",
    "                          \n",
    "print(f\"Number of samples to train on: {max_train_row}\\n\")                          \n",
    "model_dicts = select_model(income[:max_train_row], target, models_to_fit, refit_metric = 'ROC_AUC')\n",
    "\n",
    "\n",
    "print(\"model selection finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### refit = recall_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples to train on: 3256\n",
      "\n",
      "VotingClassifier\n",
      "----------------\n",
      "recall_1:0.695 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "ROC_AUC:        0.863 | 0.863\n",
      "Accuracy:       0.807 | 0.807\n",
      "recall:         0.807 | 0.807\n",
      "recall_0:       0.840 | 0.840\n",
      "\n",
      "Best Parameters: {'voting': 'soft'}\n",
      "Best Score: 0.695\n",
      "\n",
      "Time elapsed: 0.24 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "LogisticRegression\n",
      "------------------\n",
      "recall_1:0.765 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "ROC_AUC:        0.814 | 0.813\n",
      "Accuracy:       0.808 | 0.725\n",
      "recall:         0.808 | 0.725\n",
      "recall_0:       0.946 | 0.713\n",
      "\n",
      "Best Parameters: {'class_weight': 'balanced', 'solver': 'liblinear'}\n",
      "Best Score: 0.765\n",
      "\n",
      "Time elapsed: 0.04 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "GaussianNB\n",
      "----------\n",
      "recall_1:0.670 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "ROC_AUC:        0.848 | 0.848\n",
      "Accuracy:       0.807 | 0.807\n",
      "recall:         0.807 | 0.807\n",
      "recall_0:       0.847 | 0.847\n",
      "\n",
      "Best Parameters: {'var_smoothing': 1e-08}\n",
      "Best Score: 0.670\n",
      "\n",
      "Time elapsed: 0.01 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "KNeighborsClassifier\n",
      "--------------------\n",
      "recall_1:0.491 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "ROC_AUC:        0.838 | 0.669\n",
      "Accuracy:       0.817 | 0.766\n",
      "recall:         0.817 | 0.766\n",
      "recall_0:       0.919 | 0.847\n",
      "\n",
      "Best Parameters: {'algorithm': 'kd_tree', 'n_neighbors': 1, 'p': 1, 'weights': 'distance'}\n",
      "Best Score: 0.491\n",
      "\n",
      "Time elapsed: 11.94 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "BaggingClassifier\n",
      "-----------------\n",
      "recall_1:0.391 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "ROC_AUC:        0.869 | 0.849\n",
      "Accuracy:       0.822 | 0.818\n",
      "recall:         0.822 | 0.818\n",
      "recall_0:       1.000 | 0.944\n",
      "\n",
      "Best Parameters: {'bootstrap': True, 'max_features': 0.5, 'max_samples': 0.8, 'n_estimators': 5, 'warm_start': False}\n",
      "Best Score: 0.391\n",
      "\n",
      "Time elapsed: 47.59 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "GradientBoostingClassifier\n",
      "--------------------------\n",
      "recall_1:0.509 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "ROC_AUC:        0.869 | 0.822\n",
      "Accuracy:       0.826 | 0.799\n",
      "recall:         0.826 | 0.799\n",
      "recall_0:       1.000 | 0.884\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.5, 'max_features': 'log2', 'n_estimators': 20, 'random_state': 1, 'subsample': 0.1}\n",
      "Best Score: 0.509\n",
      "\n",
      "Time elapsed: 1.57 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "AdaBoostClassifier\n",
      "------------------\n",
      "recall_1:0.445 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "ROC_AUC:        0.868 | 0.867\n",
      "Accuracy:       0.822 | 0.821\n",
      "recall:         0.822 | 0.821\n",
      "recall_0:       1.000 | 0.932\n",
      "\n",
      "Best Parameters: {'algorithm': 'SAMME.R', 'learning_rate': 0.5, 'n_estimators': 100, 'random_state': 1}\n",
      "Best Score: 0.445\n",
      "\n",
      "Time elapsed: 0.58 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "DecisionTreeClassifier\n",
      "----------------------\n",
      "recall_1:0.907 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "ROC_AUC:        0.855 | 0.769\n",
      "Accuracy:       0.821 | 0.624\n",
      "recall:         0.821 | 0.624\n",
      "recall_0:       1.000 | 0.541\n",
      "\n",
      "Best Parameters: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Best Score: 0.907\n",
      "\n",
      "Time elapsed: 3.52 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "ExtraTreesClassifier\n",
      "--------------------\n",
      "recall_1:0.972 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "ROC_AUC:        0.869 | 0.848\n",
      "Accuracy:       0.827 | 0.589\n",
      "recall:         0.827 | 0.589\n",
      "recall_0:       1.000 | 0.477\n",
      "\n",
      "Best Parameters: {'class_weight': {0: 1, 1: 5}, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Score: 0.972\n",
      "\n",
      "Time elapsed: 33.96 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "RandomForestClassifier\n",
      "----------------------\n",
      "recall_1:0.923 (Metric used to choose best model)\n",
      "\n",
      "           best_value | value_best_model\n",
      "ROC_AUC:        0.869 | 0.840\n",
      "Accuracy:       0.828 | 0.632\n",
      "recall:         0.828 | 0.632\n",
      "recall_0:       0.993 | 0.547\n",
      "\n",
      "Best Parameters: {'class_weight': {0: 1, 1: 5}, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 5}\n",
      "Best Score: 0.923\n",
      "\n",
      "Time elapsed: 34.61 mins\n",
      "\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "model selection finished\n"
     ]
    }
   ],
   "source": [
    "max_train_row = int(len(income)*0.1)     \n",
    "                          \n",
    "print(f\"Number of samples to train on: {max_train_row}\\n\")                          \n",
    "model_dicts = select_model(income[:max_train_row], target, models_to_fit, refit_metric = 'recall_1')\n",
    "\n",
    "\n",
    "print(\"model selection finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 5 - cross_val_predict for best models (GradientBoostingClassifier, DecisionTreeClassifier, ExtraTreesClassifier, RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models initialized\n"
     ]
    }
   ],
   "source": [
    "best_model =  {'learning_rate': 0.05, 'max_features': 'log2', 'n_estimators': 100, 'random_state': 1, \n",
    "               'subsample': 1.0}\n",
    "model_0 = GradientBoostingClassifier()\n",
    "model_0.set_params(**best_model)  \n",
    "\n",
    "best_model =  {'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', \n",
    "               'min_samples_leaf': 19, 'min_samples_split': 2}\n",
    "model_1 = DecisionTreeClassifier()\n",
    "model_1.set_params(**best_model)  \n",
    "\n",
    "best_model =  {'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, \n",
    "               'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, \n",
    "               'n_estimators': 100, 'n_jobs': -1}\n",
    "model_2 = ExtraTreesClassifier()\n",
    "model_2.set_params(**best_model)  \n",
    "\n",
    "best_model =  {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', \n",
    "               'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1, 'random_state':1}\n",
    "\n",
    "model_3 = RandomForestClassifier()\n",
    "model_3.set_params(**best_model)  \n",
    "\n",
    "\n",
    "#Models optimized for recall_1\n",
    "best_model =  {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', \n",
    "               'min_samples_leaf': 4, 'min_samples_split': 2}\n",
    "model_4 = DecisionTreeClassifier()\n",
    "model_4.set_params(**best_model)   \n",
    "\n",
    "best_model =  {'class_weight': {0: 1, 1: 5}, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', \n",
    "               'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 5, 'n_jobs': -1}\n",
    "\n",
    "model_5 = RandomForestClassifier()\n",
    "model_5.set_params(**best_model)  \n",
    "\n",
    "print(\"models initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best models for optimized ROC_AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for GradientBoostingClassifier:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89     24720\n",
      "           1       0.71      0.49      0.58      7841\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     32561\n",
      "   macro avg       0.78      0.71      0.74     32561\n",
      "weighted avg       0.82      0.83      0.82     32561\n",
      "\n",
      "    true / pred  Low Income High Income \n",
      "     Low Income     23176.0      1544.0 \n",
      "    High Income      4001.0      3840.0 \n",
      "\n",
      "ROC_AUC: 0.883\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "Results for DecisionTreeClassifier:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88     24720\n",
      "           1       0.66      0.49      0.56      7841\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     32561\n",
      "   macro avg       0.76      0.71      0.72     32561\n",
      "weighted avg       0.81      0.82      0.81     32561\n",
      "\n",
      "    true / pred  Low Income High Income \n",
      "     Low Income     22727.0      1993.0 \n",
      "    High Income      3974.0      3867.0 \n",
      "\n",
      "ROC_AUC: 0.869\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "Results for RandomForestClassifier:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89     24720\n",
      "           1       0.74      0.41      0.52      7841\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     32561\n",
      "   macro avg       0.79      0.68      0.71     32561\n",
      "weighted avg       0.81      0.82      0.80     32561\n",
      "\n",
      "    true / pred  Low Income High Income \n",
      "     Low Income     23580.0      1140.0 \n",
      "    High Income      4658.0      3183.0 \n",
      "\n",
      "ROC_AUC: 0.877\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [model_0, model_1, model_3]\n",
    "kf = KFold(10, shuffle=True, random_state=1)\n",
    "\n",
    "for model in models:\n",
    "    predictions = cross_val_predict(model, income[optimized_columns_RFC], income[target], cv=kf, )\n",
    "    predictions = pd.Series(predictions)\n",
    "    pred_proba = cross_val_predict(model, income[optimized_columns_RFC], income[target],cv=kf,method='predict_proba')\n",
    "\n",
    "    print(f\"Results for {type(model).__name__}:\\n\")\n",
    "    print(classification_report(income[target],predictions))\n",
    "    cm = confusion_matrix(income[target],predictions)\n",
    "    myML_functions.print_cm(cm, labels=['Low Income', 'High Income'])\n",
    "    print(f\"\\nROC_AUC: {roc_auc_score(income[target], pred_proba[:,1]):0.3f}\\n\") \n",
    "    print('------------------------------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best models for optimized Recall_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for DecisionTreeClassifier:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.71      0.79     24720\n",
      "           1       0.45      0.75      0.56      7841\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     32561\n",
      "   macro avg       0.67      0.73      0.68     32561\n",
      "weighted avg       0.79      0.72      0.74     32561\n",
      "\n",
      "    true / pred  Low Income High Income \n",
      "     Low Income     17469.0      7251.0 \n",
      "    High Income      1938.0      5903.0 \n",
      "\n",
      "ROC_AUC: 0.793\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "Results for RandomForestClassifier:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.56      0.70     24720\n",
      "           1       0.39      0.90      0.55      7841\n",
      "\n",
      "   micro avg       0.64      0.64      0.64     32561\n",
      "   macro avg       0.67      0.73      0.62     32561\n",
      "weighted avg       0.81      0.64      0.66     32561\n",
      "\n",
      "    true / pred  Low Income High Income \n",
      "     Low Income     13788.0     10932.0 \n",
      "    High Income       764.0      7077.0 \n",
      "\n",
      "ROC_AUC: 0.836\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [model_4, model_5]\n",
    "kf = KFold(10, shuffle=True, random_state=1)\n",
    "\n",
    "for model in models:\n",
    "    predictions = cross_val_predict(model, income[optimized_columns_RFC], income[target], cv=kf, )\n",
    "    predictions = pd.Series(predictions)\n",
    "    pred_proba = cross_val_predict(model, income[optimized_columns_RFC], income[target],cv=kf,method='predict_proba')\n",
    "\n",
    "    print(f\"Results for {type(model).__name__}:\\n\")\n",
    "    print(classification_report(income[target],predictions))\n",
    "    cm = confusion_matrix(income[target],predictions)\n",
    "    myML_functions.print_cm(cm, labels=['Low Income', 'High Income'])\n",
    "    print(f\"\\nROC_AUC: {roc_auc_score(income[target], pred_proba[:,1]):0.3f}\\n\") \n",
    "    print('------------------------------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
